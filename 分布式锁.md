# 秒杀系统下的分布式锁


本系统关注点只在于后端技术，暂不讨论前端的相关可行操作

秒杀系统的关键在于，在多台服务器，高并发的情况下，对于共享资源的保护，在保证线程安全的前提下，还要尽可能地减少锁的粒度，以下是从三个不同的角度来实现锁对于共享资源的保护

- 基于MySQL
- 基于Redis
- 基于ZooKeeper


## Mysql实现分布式锁

使用MySQL数据库在更新数据库时，会自动加上行锁的特性，实现分布式锁，这种做法最简单，但是高并发情况下直接对数据库的访问，一旦造成MySQL数据库崩溃，对于服务器就是一场灾难。

关键SQL语句如下：

```sql
	UPDATE goods SET count = count - buyNum where count >= buyNum and id = goodsId; 

```




## Redis实现分布式锁

使用Redis集群实现分布式锁，有几个特点

- Redis集群可以缓解大量用户顺势访问一台服务器Redis的压力
- 基于内存的数据读写，性能优于MySQL数据库

实现Redis分布式锁主要使用以下几个命令

```
redis > setnx lockName exipreTime	//成功返回1，失败返回0
redis > getset lockName expireTime	//１.lockName存在返回旧值，否则抛出异常
									//2.设置lockName的新值为expireTime
redis > get lock_name				//返回lockName的过期
redis > del lock_name				//释放锁
```


值得一提的是，逻辑上获取锁的线程，并不是真正意义拥有锁,并且需要考虑到死锁的情况，以下摘自 redis.cn

```

处理死锁
以上加锁算法存在一个问题：如果客户端出现故障，崩溃或者其他情况无法释放该锁会发生什么情况？这是能够检测到这种情况，因为该锁包含一个Unix时间戳，如果这样一个时间戳等于当前的Unix时间，该锁将不再有效。

当以下这种情况发生时，我们不能调用DEL来删除该锁，并且尝试执行一个SETNX，因为这里存在一个竞态条件，当多个客户端察觉到一个过期的锁并且都尝试去释放它。

C1 和 C2 读lock.foo检查时间戳，因为他们执行完SETNX后都被返回了0，因为锁仍然被 C3 所持有，并且 C3 已经崩溃。
C1 发送DEL lock.foo
C1 发送SETNX lock.foo命令并且成功返回
C2 发送DEL lock.foo
C2 发送SETNX lock.foo命令并且成功返回
错误：由于竞态条件导致 C1 和 C2 都获取到了锁
幸运的是，可以使用以下的算法来避免这种情况，请看 C4 客户端所使用的好的算法：

C4 发送SETNX lock.foo为了获得该锁
已经崩溃的客户端 C3 仍然持有该锁，所以Redis将会返回0给 C4
C4 发送GET lock.foo检查该锁是否已经过期。如果没有过期，C4 客户端将会睡眠一会，并且从一开始进行重试操作
另一种情况，如果因为 lock.foo键的Unix时间小于当前的Unix时间而导致该锁已经过期，C4 会尝试执行以下的操作：

GETSET lock.foo <current Unix timestamp + lock timeout + 1>
由于GETSET 的语意，C4会检查已经过期的旧值是否仍然存储在lock.foo中。如果是的话，C4 会获得锁
如果另一个客户端，假如为 C5 ，比 C4 更快的通过GETSET操作获取到锁，那么 C4 执行GETSET操作会被返回一个不过期的时间戳。C4 将会从第一个步骤重新开始。请注意：即使 C4 在将来几秒设置该键，这也不是问题。
为了使这种加锁算法更加的健壮，持有锁的客户端应该总是要检查是否超时，保证使用DEL释放锁之前不会过期，因为客户端故障的情况可能是复杂的，不止是崩溃，还会阻塞一段时间，阻止一些操作的执行，并且在阻塞恢复后尝试执行DEL（此时，该LOCK已经被其他客户端所持有）
```

实现细节

```java
if(checkIfLockTimeout(mutex, now)){
    String expect = jedisClusterUtil._get(mutex);
    String preExpireTime = jedisClusterUtil._getSet(mutex, expireTime);
    if(preExpireTime != null && preExpireTime.equals(expect)){
        return true;
    }
}
return false;
```


## Zookeeper实现分布式锁

在网上搜索到几个关于Zookeeper实现分布式锁的博客，其中包括使用Lock接口、原生Synchronized锁来实现的，在这里我使用一种更为简单易懂的方式来实现。

- 节点监听器
- 羊群效应
- 线程本地变量
- 一个Bug

### 节点监听器

多线程竞争同一资源的场景下，我们希望一个节点在释放锁之后，其他线程可以感知到这一情况，从而获取到锁，这里使用Curator框架的CacheNode来实现未获取锁的线程监听获取锁的线程。

```java
final String watchPath = prevNode;
final NodeCache cache = new NodeCache(client, watchPath, false);
cache.start(true);
cache.getListenable().addListener(new NodeCacheListener() {
    @Override
    public void nodeChanged() throws Exception {
        ...
    }
});
```

### 羊群效应

如果让所有未获取锁的线程监听同一个获取锁的线程X，一旦线程X释放锁之后，所有监听在该线程上的线程都会收到通知，并且同时去竞争资源，而结果每次都只会有一个线程获取到锁，这对于CPU来说是极其耗费资源的。

使用Zookeepr创建临时顺序节点的特性，每个竞争线程可以等待排在其线程前面的最小值，避免不必要的大量竞争。

```java
List<String> brotherNodes = client.getChildren().forPath(path);
Collections.sort(brotherNodes);

String prevNode = null;
for(int i = brotherNodes.size()-1; i >= 0; --i){
    if(brotherNodes.get(i).compareTo(index) < 0){
        prevNode = this.prefix + brotherNodes.get(i);
        break;
    }
}
```


### 线程本地变量

在高并发竞争资源的情况下，多个线程在Zookeepr建立多个临时顺序节点，节点A释放锁的实现，还必须删除自身的节点，从而唤醒下一节点。

```java
try{
	zookeeperLock.lock();
}catch(){
	//...
}finally{
	zookeeper.unlock();
}
```

为了在删除节点的线程中保存，使用节点的信息，可以使用TreadLocl来保存当前节点的路径。

```java
    threadLocalPath.set(currentLock);
	...
	String currentPath = threadLocalPath.get();
	
```

### 一个Bug

有一种极端情况是：当前节点发现自己并不是最小的节点，它会将前一个节点加入监听器，就在此时前一个节点被删除，根据NodeCache的特性：

NodeCache不仅可以用于监听数据节点内容变更，也能监听指定节点是否存在。如果原本节点不存在，那么cache就会在节点创建后触发NodeCacheListener,但是如果该节点被删除，那么Curator就无法触发NodeCacheListener了。

也就是说，当前节点将一个被删除的节点（并且不可能再次被创建）作为监听节点，当前节点绝对不可能等到监听事件的发生。

为了解决这个Bug，可以在添加监听器之后，再次判断被监听节点是否存在，如果不存在了，当前线程就可以离开lock()阻塞函数。当然，我们只要捕获重复删除节点的异常即可。

```java
try {
    Stat stat = client.checkExists().forPath(prevNode);
    if (stat == null) {
        localPath.set(currentLock);
        latch.countDown();
    }
}catch (Exception e){
    logger.error("防止prevNode被删除，currentLock永远监听的Bug," + e.getMessage());
    e.printStackTrace();
}
```


## 完整代码

**Mysql分布式锁**

```java
package com.ackerman.utils;

import com.ackerman.dao.MysqlLockDao;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;


public class MysqlLock {
    private static Logger logger = LoggerFactory.getLogger(MysqlLock.class);

    private final MysqlLockDao mysqlLockDao;
    private final String mutex;
    private final int remain;

    public MysqlLock(String mutex, int goodsNum){
        this.mysqlLockDao = SpringContextContainer.getBean(MysqlLockDao.class);
        this.mutex = mutex;
        this.remain = goodsNum;

        try{
            if(mysqlLockDao.checkLockIfExist(mutex) != null){
                mysqlLockDao.resetLock(mutex, remain);
            }
            else{
                mysqlLockDao.insertLock(mutex, remain);
            }
        }catch (Exception e){
            logger.error("创建Mysql异常");
            e.printStackTrace();
        }
    }

    /**
     * @param mutex 用户购买的商品
     * @param buys 购买的数量
     * @return 购买成功返回true
     * @desp 其实这里并没有加锁操作，纯粹是利用数据库行锁的特性
     *
     */
    public boolean tryLockAndBuy(String mutex, int buys){
        try{
            if(mysqlLockDao.tryUpdate(mutex, buys) == 0){
                return false;
            }
            return true;
        }catch (Exception e){
            logger.error("购买商品异常：" + mutex + ", " + e.getMessage());
        }
        return false;
    }

}
```


```java
package com.ackerman.dao;

import org.apache.ibatis.annotations.*;

@Mapper
public interface MysqlLockDao {
    public static final String TABLE = "seckill_goods";
    public static final String INSERT_FIELDS = "mutex, remain";
    public static final String SELECT_FIELDS = "id, " + INSERT_FIELDS;


    @Select({"INSERT INTO ", TABLE, " (mutex, remain) VALUES( #{mutex}, #{remain})"})
    public void insertLock(@Param("mutex") String mutex, @Param("remain") int remain);

    @Select({"SELECT remain FROM ", TABLE, " WHERE mutex = #{mutex}"})
    public Object checkLockIfExist(String mutex);

    @Select({"SELECT remain FROM ", TABLE, " WHERE mutex = #{mutex}"})
    public int queryRemain(String mutex);


    @Update({"UPDATE ", TABLE, " SET remain = #{remain} WHERE mutex = #{mutex}"})
    public int resetLock(@Param("mutex") String mutex, @Param("remain") int remain);

    @Update({"UPDATE ", TABLE, "SET remain = remain - #{buy} WHERE remain >= #{buy} and mutex = #{mutex}"})
    public int tryUpdate(@Param("mutex") String mutex, @Param("buy") int buy);

}

```


**Redis分布式锁**

```java
package com.ackerman.utils;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import java.util.Random;

public class RedisLock {
    private static Logger logger = LoggerFactory.getLogger(RedisLock.class);

    private static RedisUtil redisUtil = SpringContextContainer.getBean(RedisUtil.class);

    private Random random = new Random(47);
    private final String mutex;
    private long interval;  //ms 锁 最多被占有的时间, 如果持有锁的线程死掉，其他线程就可以抢占
    private long timeout;   //ms 锁 最多等待获取的最长时间

    public RedisLock(String mutex,long interval, long timeout){
        this.mutex = mutex;
        this.interval = interval;
        this.timeout = timeout;
        init();
    }

    public RedisLock(String mutex){
        this(mutex, 5000, 1000);
    }


    private void init(){
        try{
            if(redisUtil._get(mutex) != null){
                redisUtil._del(mutex);
            }
        }catch (Exception e){
            logger.error("Redis锁初始化出错");
            e.printStackTrace();
        }
    }

    /**
     * @param timeout ms 尝试获取锁的时间
     * @return 是否获得分布式锁
     */
    public boolean tryLock(long timeout){
        Long current = System.currentTimeMillis();
        try{
            while (true){
                if((System.currentTimeMillis() - current) > timeout){
                    break;
                }
                else{
                    if(innerTryLock()){
                        return true;
                    }
                    else{
                        Thread.sleep(200 + this.random.nextInt(40));
                    }
                }
            }
        }catch (Exception e){
            logger.error("尝试获取Redis分布式锁异常：" + e.getMessage());
        }

        return false;
    }

    public boolean tryLock(){
        return tryLock(this.timeout);
    }


    private boolean innerTryLock(){
        try{
            long now = System.currentTimeMillis();
            String expireTime = String.valueOf(now + this.interval);
            if(redisUtil._setnx(this.mutex, expireTime) == 1){
                return true;
            }
            else{
                if(checkIfLockTimeout(now)){
                    String expect = redisUtil._get(this.mutex);
                    String preExpireTime = redisUtil._getSet(this.mutex, expireTime);
                    if(preExpireTime != null && preExpireTime.equals(expect)){
                        return true;
                    }
                }
                return false;
            }
        }catch (Exception e){
            e.printStackTrace();
        }

        return false;
    }

    public void unLock(){
        redisUtil._del(this.mutex);
    }


    /**
     * @param timeStamp 当前时间戳
     * @return 检查分布式锁是否过期
     *
     * 在高并发的情况下，会经常抛出异常
     * 原因是其他线程_del锁，而本线程调用了_get
     */
    private boolean checkIfLockTimeout(long timeStamp){
        try{
            return  timeStamp > Long.valueOf(redisUtil._get(this.mutex));
        }catch (Exception e){
//            logger.error("检查过期时间异常, mutex=" + this.mutex);
//            e.printStackTrace();
        }
        return true;
    }
}

```

**Zookeeper分布式锁**

```java
package com.ackerman.utils;

import org.apache.curator.RetryPolicy;
import org.apache.curator.framework.CuratorFramework;
import org.apache.curator.framework.CuratorFrameworkFactory;
import org.apache.curator.framework.recipes.cache.NodeCache;
import org.apache.curator.framework.recipes.cache.NodeCacheListener;
import org.apache.curator.retry.ExponentialBackoffRetry;
import org.apache.zookeeper.CreateMode;
import org.apache.zookeeper.data.Stat;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Collections;
import java.util.List;
import java.util.concurrent.CountDownLatch;

/*
    /zk-locks
             /milk
                  /number-1
                  /number-2
                  /number-3
                  .
                  .
                  .

            /apple
                  /number-1
                  /number-2
                  .
                  .
                  .
 */
public class ZookeeperLock {
    private static Logger logger = LoggerFactory.getLogger(ZookeeperLock.class);
    private static final String connectString = "127.0.0.1:2181";
    private static final String ROOT_PATH = "/zk-locks";
    private static final String NUMBER = "/number-";
    private static int sessionTimeout = 40000;
    private static int connectTimeout = 20000;
    private static RetryPolicy retryPolicy = new ExponentialBackoffRetry(5000, 5);
    private final CuratorFramework client;
    private final String mutex;
    private final String prefix;
    private final ThreadLocal<String> threadLocalPath;

    public ZookeeperLock(String mutex){
        this.mutex = "/" + mutex;
        this.prefix = ROOT_PATH + "/" + mutex + "/";
        this.threadLocalPath = new ThreadLocal<String>();
        client = CuratorFrameworkFactory.newClient(connectString, sessionTimeout, connectTimeout, retryPolicy);
        client.start(); //阻塞函数
    }


    public void close(){
        try{
            client.close();
        }catch (Exception e){
            e.printStackTrace();
        }
    }

    public void lock(){
        try{
            final String currentLock = client.create()
                    .creatingParentsIfNeeded()
                    .withMode(CreateMode.EPHEMERAL_SEQUENTIAL)
                    .forPath(ROOT_PATH + mutex + NUMBER);
            String index = currentLock.substring(currentLock.lastIndexOf("/")+1);
            List<String> brotherNodes = client.getChildren().forPath(ROOT_PATH + mutex);
            Collections.sort(brotherNodes);

            String prevNode = null;
            for(int i = brotherNodes.size()-1; i >= 0; --i){
                if(brotherNodes.get(i).compareTo(index) < 0){
                    prevNode = this.prefix + brotherNodes.get(i);
                    break;
                }
            }

//            System.out.println("**********************************************************");
//            System.out.println(Thread.currentThread().getName() + "-创建节点:" + index + ", 前一个节点是:" + prevNode);
//            System.out.println("**********************************************************");

            threadLocalPath.set(currentLock);
            if(prevNode == null){
                return;
            }
            else{
                final CountDownLatch latch = new CountDownLatch(1);
                final String watchPath = prevNode;
                final NodeCache cache = new NodeCache(client, watchPath, false);
                cache.start(true);
                cache.getListenable().addListener(new NodeCacheListener() {
                    @Override
                    public void nodeChanged() throws Exception {
                        latch.countDown();
                    }
                });

                //bug ... 添加prevNode节点为监听监听节点时，节点已被删除，此时的currentPath无法被唤醒，
                try {
                    Stat stat = client.checkExists().forPath(prevNode);
                    if (stat == null) {
                        threadLocalPath.set(currentLock);
                        latch.countDown();
                    }
                }catch (Exception e){
                    logger.error("防止prevNode被删除，currentLock永远监听的Bug," + e.getMessage());
                    e.printStackTrace();
                }
                latch.await();
            }

        }catch (Exception e){
            logger.error("获取zookeeper锁异常: " + e.getMessage());
            e.printStackTrace();
        }
    }

    public void unlock(){
        try{
            String currentPath = threadLocalPath.get();
            if(currentPath != null && client.checkExists().forPath(currentPath) != null){
                client.delete().guaranteed().forPath(currentPath);
            }
        }catch (Exception e){
            logger.error("释放zookeeper分布式锁出错：" + e.getMessage());
            e.printStackTrace();
        }
    }
}

```